{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596391223456",
   "display_name": "Python 3.7.0 64-bit ('brainlit': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.utils.swc import get_sub_neuron, graph_to_paths\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Brain data tutorial\n",
    "We have prepared a 2 low-resolution brain volumes, as well as a single axon segment, at the below s3 urls (see `uploading_brains.ipynb`).\n",
    "The method demonstrated below pulls a region of the volume around an annotated axon point set by the user.\n",
    "\n",
    "## 1) Define Variables\n",
    "- `mip` ranges from higher resolution (0) to lower resolution (1).\n",
    "- `v_id` are vertex ids ranging from the soma (0) to the end of the axon (1649).\n",
    "- `radius` is the radius to pull around the selected point, in voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"s3://\"\n",
    "dir = p + \"mouse-light-viz/precomputed_volumes/brain1_lowres\"\n",
    "dir_segments = p + \"mouse-light-viz/precomputed_volumes/brain1_lowres_segments\"\n",
    "mip = 0\n",
    "v_id = 300\n",
    "radius = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a NeuroglancerSession instance and download the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading:  88%|████████▊ | 7/8 [00:18<00:01,  1.87s/it]\n\nDownloaded volume is of shape (151, 151, 151), with total intensity 4609107.\n"
    }
   ],
   "source": [
    "# get image and center point\n",
    "ngl_sess = NeuroglancerSession(mip = mip, url = dir, url_segments=dir_segments)\n",
    "img, bbox, vox = ngl_sess.pull_voxel(2, v_id, radius, radius, radius)\n",
    "print(f\"\\n\\nDownloaded volume is of shape {img.shape}, with total intensity {sum(sum(sum(img)))}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Generate a graph from the segment data within the volume, and convert it to paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Selected volume contains 824 nodes and 119 paths\n"
    }
   ],
   "source": [
    "G_sub = ngl_sess.get_segments(2, bbox)\n",
    "paths = graph_to_paths(G_sub)\n",
    "print(f\"Selected volume contains {G_sub.number_of_nodes()} nodes and {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) View the volume with paths overlaid via napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_shapes(data=paths, shape_type='path', edge_width=0.1, edge_color='blue', opacity=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}