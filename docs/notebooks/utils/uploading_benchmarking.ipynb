{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils import upload_benchmarking\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Benchmarking Images from local data locations .\n",
    "This notebook demonstrates uploading the benchmarking data and associated `.swc` segment files.\n",
    "The upload destination could easily be set to a url of a cloud data server such as s3.\n",
    "\n",
    "## 1) Define variables.\n",
    " - `source` and `source_segments` are the root directories of the octree-formatted data and swc files.\n",
    " - `p` is the prefix string. `file://` indicates a filepath, while `s3://` or `gc://` indicate URLs.\n",
    " - `dest` and `dest_segments` are the destinations for the uploads (in this case, filepaths).\n",
    " - `num_res` denotes the number of resolutions to upload. If uploading .tif files that aren't very large or where only one resolution is necessary, set num_res to 1. \n",
    " \n",
    "The below paths lead to sample data in my local drive (will be updated to reflect download from S3). Alter the below path definitions to point to your own local file locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = (Path().resolve().parents[5] / \"Downloads\" / \"1\").as_posix()\n",
    "dest = \"s3://open-neurodata/benchmarking_data/1\"\n",
    "dest_segments = \"s3://open-neurodata/benchmarking_data/1\"\n",
    "num_res = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Upload the image data (.tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing files.\n",
      "Starting upload.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a87c4c0e0240699763b502804e476c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Creating precomputed volume at layer index 0', max=1.0, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finished layer index 0, took 6.217748165130615 seconds\n"
     ]
    }
   ],
   "source": [
    "upload_benchmarking.upload_volumes(source, dest, num_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the upload fails with the error: `timed out on a chunk on layer index 0. moving on to the next step of pipeline`, re-run the `upload_volumes` function but with the `continue_upload` parameter, which takes `layer index` (the layer index said in the error message) and `image index` (the last succesful image that uploaded).  \n",
    "\n",
    "For example, if the output failed after image 19, then run \n",
    "`upload_benchmarking.upload_volumes(source, dest, num_res, continue_upload = (0, 19))`. Repeat this till all of the upload is complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Upload the segmentation data (.swc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b23aaf17ca4536b66e2b06763b90f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='converting swcs to neuroglancer format...', max=10.0, sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 19.91it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 14.58it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 18.72it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 15.61it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 18.29it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 20.93it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 20.21it/s]\n",
      "Uploading: 100%|██████████████████████████████████████| 1/1 [00:00<00:00, 15.92it/s]\n"
     ]
    }
   ],
   "source": [
    "upload_benchmarking.upload_segments(source, dest_segments, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
