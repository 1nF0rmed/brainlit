{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook explains how to:\n",
    "(1) download raw benchmarking data to your local computer \n",
    "\n",
    "(2) read raw benchmarking data from S3\n",
    "\n",
    "(3) read precomputed volume/skeleton benchmarking data via Neuroglancer\n",
    "\n",
    "#### Quick notes on the benchmarking data:\n",
    "\n",
    "In octree format, data is labled in folders 1-50. 1-25 correspond with the 1-25 \"test\" raw data and 26-50 correspond with the 1-25 \"validation\" raw data\n",
    "\n",
    "Known issues with a few of the files: \n",
    "\n",
    "- test_10 (#10),test_9 (#9) - didnt seem to have good swc alignment\n",
    "\n",
    "- test_24 (#24) - issues with the image\n",
    "\n",
    "- validation_11 (#37) - seems to be a shift between swcs and the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Raw Benchmarking Data with AWS CLI\n",
    "\n",
    "###### This will download the benchmarking data in .tif and .swc format to a local computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Installing AWS CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can install AWS CLI for any major operating system:\n",
    "\n",
    "#### macOS \n",
    "(the full documentation uses pip, but Homebrew works more seamlessly):\n",
    "Documentation: https://docs.aws.amazon.com/cli/latest/userguide/cli-install-macos.html \n",
    "\n",
    "```brew install awscli```\n",
    "#### Linux \n",
    "Documentation: https://docs.aws.amazon.com/cli/latest/userguide/awscli-install-linux.html \n",
    "\n",
    "```$ pip install awscli```\n",
    "\n",
    "#### Windows\n",
    "Documentation: https://docs.aws.amazon.com/cli/latest/userguide/awscli-install-windows.html\n",
    "Installer: http://docs.aws.amazon.com/cli/latest/userguide/awscli-install-windows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Configuring AWS CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ```aws configure``` in any command line and follow the prompts.\n",
    "\n",
    "You will be asked for \n",
    "- AWS Access Key ID\n",
    "- AWS Secrety Access Key\n",
    "- Default Region Name: us-east-1, us-east-2, us-west-1, us-west-2, ...\n",
    "- Default output format: json, table, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Downloading .tif files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command ```aws s3 sync s3://open-neurodata/brainlit/benchmarking_data/tif-files/ sample-tif-location```\n",
    "\n",
    "Replace \"sample-tif-location\" with your respective download destination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Accessing AND Visualizing .tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loops through and reads the .tif files in the download directory. Alter data_dir to point to your download location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "data_dir = Path().resolve().parents[5] / \"Downloads\" / \"sample-tif-location\"\n",
    "im_files = list(data_dir.glob(\"**/*.tif\"))\n",
    "\n",
    "for im_num, im_file in enumerate(im_files):\n",
    "    print(f\"Image {im_num}/{len(im_files)}\")\n",
    "    print(im_file)\n",
    "    f = im_file.parts[-1][:-8] + \"-gfp.tif\" \n",
    "    im = io.imread(im_file, plugin=\"tifffile\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code can visualize a specified .tif file. To visualize tif files with .swc overlaid, run the data through the image mask generation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "file_name = \"test_10-gfp.tif\" # Can change to any image (test 1-25, validation 1-25)\n",
    "\n",
    "im_file = data_dir / file_name\n",
    "im = io.imread(im_file, plugin=\"tifffile\") \n",
    "    \n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Downloading .swc files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the command ```aws s3 sync s3://open-neurodata/brainlit/benchmarking_data/Manual-GT/ sample-tif-location/sample-swc-location```\n",
    "\n",
    "Replace \"sample-swc-location\" with your respective download destination. Keep it within the .tif folder to maintain octree format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Accessing .swc files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loops through the .swc files in the download directory. Alter data_dir to point to your file download location.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "data_dir = Path().resolve().parents[5] / \"Downloads\" / \"sample-swc-location\" \n",
    "swc_files = list(data_dir.glob(\"**/*.swc\"))\n",
    "\n",
    "for swc_num, swc_file in enumerate(swc_files):\n",
    "    print(f\"SWC {swc_num}/{len(swc_files)}\")\n",
    "    print(swc_file)\n",
    "    image_name = swc_file.parts[6]\n",
    "    swc_num = swc_file.parts[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mouselight_code.src.benchmarking_params import brain_offsets, vol_offsets, scales, type_to_date\n",
    "from mouselight_code.src import read_swc\n",
    "from brainlit.utils.swc import df_to_graph, graph_to_paths\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from mouselight_code.src.visualize import napari_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = Path(\"C:/Users/shrey/Downloads/sample-tif-location\")\n",
    "\n",
    "gfp_files = list(im_dir.glob(\"**/*-gfp.tif\"))\n",
    "\n",
    "swc_base_path = im_dir / \"sample-swc-location\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_num, im_path in enumerate(gfp_files):\n",
    "    \n",
    "    print(f\"Image {im_num+1}/{len(gfp_files)}\")\n",
    "    print(im_path)\n",
    "    \n",
    "    f = im_path.parts[-1][:-8].split(\"_\")\n",
    "    image = f[0]\n",
    "    date = type_to_date[image]\n",
    "    num = int(f[1])\n",
    "\n",
    "    scale = scales[date]\n",
    "    brain_offset = brain_offsets[date]\n",
    "    vol_offset = vol_offsets[date][num]\n",
    "    im_offset = np.add(brain_offset, vol_offset)\n",
    "\n",
    "    lower = int(np.floor((num - 1) / 5) * 5 + 1)\n",
    "    upper = int(np.floor((num - 1) / 5) * 5 + 5)\n",
    "    dir1 = date + \"_\" + image + \"_\" + str(lower) + \"-\" + str(upper)\n",
    "    dir2 = date + \"_\" + image + \"_\" + str(num)\n",
    "    swc_path = swc_base_path / dir1 / dir2\n",
    "\n",
    "    swc_files = list(swc_path.glob(\"**/*.swc\"))\n",
    "    im = io.imread(im_path, plugin=\"tifffile\")\n",
    "    print(f\"Image shape: {im.shape}\")\n",
    "\n",
    "    paths_total = []\n",
    "    for swc_num, swc in enumerate(swc_files):\n",
    "        if \"cube\" in swc.parts[-1]:\n",
    "            # skip the bounding box swc\n",
    "            continue\n",
    "\n",
    "        df, swc_offset, _, _, _ = read_swc.read_swc(swc)\n",
    "\n",
    "        offset_diff = np.subtract(swc_offset, im_offset)\n",
    "        G = df_to_graph(df)\n",
    "\n",
    "        paths = graph_to_paths(G)\n",
    "       \n",
    "        for path_num, p in enumerate(paths):\n",
    "            pvox = (p + offset_diff) / (scale) * 1000\n",
    "            paths_total.append(pvox)\n",
    "            \n",
    "        napari_viewer(np.swapaxes(im,0,2), shapes=paths_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read benchmarking data from S3 with boto3\n",
    "###### This will load the benchmarking .tif images from S3 and can either display them on napari or a local image viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Install and configure boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip install boto3 if not previously installed.\n",
    "Save a credentials file in ```~/.aws/credentials.ini```\n",
    "\n",
    "\n",
    "File format: \n",
    "\n",
    "[default]\n",
    "\n",
    "aws_access_key_id = xxxxxxxxxxxxxxxx\n",
    "\n",
    "aws_secret_access_key = xxxxxxxxxxxxxxxxxxxxxxxx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read the .tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "\n",
    "f_list = ['test_1-gfp.tif', 'test_2-gfp.tif', 'test_3-gfp.tif', 'test_4-gfp.tif', 'test_5-gfp.tif', 'test_6-gfp.tif',\n",
    " 'test_7-gfp.tif', 'test_8-gfp.tif', 'test_9-gfp.tif', 'test_10-gfp.tif', 'test_11-gfp.tif', 'test_12-gfp.tif',\n",
    " 'test_13-gfp.tif', 'test_14-gfp.tif', 'test_15-gfp.tif', 'test_16-gfp.tif', 'test_17-gfp.tif', 'test_18-gfp.tif',\n",
    " 'test_19-gfp.tif', 'test_20-gfp.tif', 'test_21-gfp.tif', 'test_22-gfp.tif', 'test_23-gfp.tif', 'test_24-gfp.tif',\n",
    " 'test_25-gfp.tif', 'validation_1-gfp.tif', 'validation_2-gfp.tif', 'validation_3-gfp.tif', 'validation_4-gfp.tif',\n",
    " 'validation_5-gfp.tif', 'validation_6-gfp.tif', 'validation_7-gfp.tif', 'validation_8-gfp.tif', 'validation_9-gfp.tif',\n",
    " 'validation_10-gfp.tif', 'validation_11-gfp.tif', 'validation_12-gfp.tif', 'validation_13-gfp.tif', 'validation_14-gfp.tif',\n",
    " 'validation_15-gfp.tif', 'validation_16-gfp.tif', 'validation_17-gfp.tif', 'validation_18-gfp.tif', 'validation_19-gfp.tif',\n",
    " 'validation_20-gfp.tif', 'validation_21-gfp.tif', 'validation_22-gfp.tif', 'validation_23-gfp.tif', 'validation_24-gfp.tif',\n",
    " 'validation_25-gfp.tif']\n",
    "\n",
    "#HOME = Path(\"C:/Users/shrey\") #Change to specify Home directory if aws config file is not being found.\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket('open-neurodata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and Visualize a specific .tif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = 'test_10-gfp.tif' #Replace with specific .tif file name\n",
    "print('File name: ', file)\n",
    "\n",
    "prefix = 'benchmarking_data/tif-files/' + file\n",
    "objects = my_bucket.objects.filter(Prefix = prefix)\n",
    "  \n",
    "for obj in objects:\n",
    "    path, filename = os.path.split(obj.key)\n",
    "    im = Image.open(obj.get()['Body'])\n",
    "    im.show() # Can't visualize on Napari yet (?) but this line will launch image in local image viewer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image to Numpy Array: ') #converting to numpy array\n",
    "print(np.array(im))\n",
    "\n",
    "print('File: ', file) #viewing image in notebook\n",
    "im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can't vizualize in napari YET, \"TypeError: 'TiffImageFile' object is not iterable\"\n",
    "import napari\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(im)\n",
    "    #viewer.add_labels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read ALL 50 .tif files & visualize on local image viewer\n",
    "Files should pop up in local image viewer (For Windows, it's the Photos app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for file in f_list:\n",
    "    print('File name: ', file)\n",
    "    prefix = 'benchmarking_data/tif-files/' + file\n",
    "    objects = my_bucket.objects.filter(Prefix=prefix)\n",
    "    \n",
    "    for obj in objects:\n",
    "        path, filename = os.path.split(obj.key)\n",
    "        im = Image.open(obj.get()['Body'])\n",
    "        im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read benchmarking data from S3 with Neuroglancer\n",
    "###### This will load the benchmarking data from precomputed volume and skeleton form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainlit.utils import session, upload_benchmarking\n",
    "dest = \"s3://open-neurodata/brainlit/benchmarking_data/test\"\n",
    "dest_segments = \"s3://open-neurodata/brainlit/benchmarking_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess._get_voxel(1,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "sess = session.NeuroglancerSession(url=dest, url_segments=dest_segments, mip=0)  # create session object object\n",
    "#img, bounds, vox = sess.pull_chunk(1, 1, 1)\n",
    "#img, bbox, vox = sess.pull_voxel(2, v_id = 1, radius = 0)\n",
    "#img, bounds, vertices = sess.pull_vertex_list(1, list(range(1,187)), 0, expand=False)  # get image containing some data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = sess.get_segments(1, bbox = [330,300,100])\n",
    "paths = graph_to_paths(G)\n",
    "print(f\"Selected volume contains {G.number_of_nodes()} nodes and {len(paths)} paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_shapes(data=paths, shape_type='path', edge_width=0.1, edge_color='blue', opacity=0.1)\n",
    "    viewer.add_points(vox, size=1, opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc, Ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mouselight_code.src.benchmarking_params import brain_offsets, vol_offsets, scales, type_to_date\n",
    "from mouselight_code.src import read_swc\n",
    "from brainlit.utils.swc import df_to_graph, graph_to_paths\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from mouselight_code.src.visualize import napari_viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "brain_offsets = {\n",
    "    \"10-01\": [69445.19581378, 12917.40798423, 30199.63896704],\n",
    "    \"8-01\": [70093.27584462, 15071.5958194, 29306.73645404],\n",
    "}\n",
    "vol_offsets = {\n",
    "    \"10-01\": {\n",
    "        1: [3944.427317, 1689.489974, 2904.058044],\n",
    "        2: [7562.41721, 2517.659516, 6720.099583],\n",
    "        3: [6440.344565, 3724.653335, 3315.921558],\n",
    "        4: [3693.850008, 4690.851133, 4759.545202],\n",
    "        5: [2176.050385, 4472.356622, 5422.519379],\n",
    "        6: [5186.880558, 1607.205131, 5627.930585],\n",
    "        7: [4474.380558, 3801.205131, 5641.030585],\n",
    "        8: [8625.680558, 3461.805131, 7853.730585],\n",
    "        9: [8036.380558, 2739.005131, 7646.730585],\n",
    "        10: [8908.480558, 2241.305131, 5275.430585],\n",
    "        11: [5763.576767, 920.389294, 6949.146129],\n",
    "        12: [4395.108079, 3142.101761, 7674.109968],\n",
    "        13: [6357.017903, 3962.134266, 1793.497497],\n",
    "        14: [1290.816602, 3784.927683, 5489.762402],\n",
    "        15: [3261.686282, 4042.901892, 2753.811915],\n",
    "        16: [6434.371327, 3146.622337, 5511.826519],\n",
    "        17: [8759.453985, 3140.594903, 8062.858693],\n",
    "        18: [3647.85608, 4787.29009, 5026.415948],\n",
    "        19: [6278.469831, 1981.820562, 2234.779833],\n",
    "        20: [2202.332629, 3856.654157, 2746.457209],\n",
    "        21: [6119.880378, 3134.567468, 4973.882337],\n",
    "        22: [7348.575311, 1596.96885, 3394.721975],\n",
    "        23: [6633.877456, 2001.108354, 7079.429486],\n",
    "        24: [6226.801328, 4177.61506, 3591.197682],\n",
    "        25: [6270.405961, 4555.535222, 3526.056004],\n",
    "    },\n",
    "    \"8-01\": {\n",
    "        1: [3808.881423, 2359.223225, 5006.26702],\n",
    "        2: [6889.089085, 2566.530453, 8891.683733],\n",
    "        3: [7128.395228, 1863.63414, 9648.801312],\n",
    "        4: [5482.231871, 4208.245402, 11971.55106],\n",
    "        5: [6671.293606, 3960.755275, 9643.859292],\n",
    "        6: [5762.10132, 3843.673284, 5200.517052],\n",
    "        7: [6337.40132, 4651.873284, 3297.317052],\n",
    "        8: [5744.50132, 2051.973284, 5214.317052],\n",
    "        9: [4518.90132, 1426.273284, 6342.517052],\n",
    "        10: [4765.10132, 4331.973284, 9779.817052],\n",
    "        11: [8681.046946, 3866.08193, 9473.853778],\n",
    "        12: [3311.148546, 2486.773487, 9180.297745],\n",
    "        13: [4844.082155, 1247.496358, 9977.939894],\n",
    "        14: [5799.812932, 3939.750578, 8438.994633],\n",
    "        15: [4774.172495, 2561.964214, 4977.603299],\n",
    "        16: [4698.885169, 2982.058156, 7392.274638],\n",
    "        17: [5052.616098, 4900.487158, 2202.164446],\n",
    "        18: [4697.092614, 6292.276653, 1738.6029],\n",
    "        19: [3954.675928, 2249.329085, 10126.20052],\n",
    "        20: [3368.211559, 4350.103211, 6341.601026],\n",
    "        21: [2275.350296, 2058.764732, 9266.288906],\n",
    "        22: [6348.036119, 2952.529814, 10122.2469],\n",
    "        23: [3842.043698, 4089.827617, 7974.444682],\n",
    "        24: [73194, 15978.7, 35029.3],\n",
    "        25: [5878.386609, 2172.311862, 5313.66071],\n",
    "    },\n",
    "}\n",
    "\n",
    "scales = {\n",
    "    \"10-01\": np.array([298.66187, 301.37174, 1050.67223]),\n",
    "    \"8-01\": np.array([298.75923295, 304.41589844, 988.40414663]),\n",
    "}\n",
    "\n",
    "\n",
    "type_to_date = {\"validation\": \"10-01\", \"test\": \"8-01\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = Path(\"C:/Users/shrey/Downloads/test\")\n",
    "\n",
    "gfp_files = list(im_dir.glob(\"**/*-gfp.tif\"))\n",
    "\n",
    "swc_base_path = im_dir / \"Manual-GT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for every image\n",
    "for im_num, im_path in enumerate(gfp_files):\n",
    "\n",
    "\n",
    "    print(f\"Image {im_num+1}/{len(gfp_files)}\")\n",
    "    print(im_path)\n",
    "    \n",
    "    f = im_path.parts[-1][:-8].split(\"_\")\n",
    "    image = f[0]\n",
    "    date = type_to_date[image]\n",
    "    num = int(f[1])\n",
    "\n",
    "    #read appropriate parameters\n",
    "    scale = scales[date]\n",
    "    brain_offset = brain_offsets[date]\n",
    "    vol_offset = vol_offsets[date][num]\n",
    "    im_offset = np.add(brain_offset, vol_offset)\n",
    "\n",
    "    lower = int(np.floor((num - 1) / 5) * 5 + 1)\n",
    "    upper = int(np.floor((num - 1) / 5) * 5 + 5)\n",
    "    dir1 = date + \"_\" + image + \"_\" + str(lower) + \"-\" + str(upper)\n",
    "    dir2 = date + \"_\" + image + \"_\" + str(num)\n",
    "    swc_path = swc_base_path / dir1 / dir2\n",
    "\n",
    "    swc_files = list(swc_path.glob(\"**/*.swc\"))\n",
    "    im = io.imread(im_path, plugin=\"tifffile\")\n",
    "    print(f\"Image shape: {im.shape}\")\n",
    "\n",
    "    paths_total = []\n",
    "    for swc_num, swc in enumerate(swc_files):\n",
    "        if \"cube\" in swc.parts[-1]:\n",
    "            # skip the bounding box swc\n",
    "            continue\n",
    "\n",
    "        df, swc_offset, _, _, _ = read_swc.read_swc(swc)\n",
    "\n",
    "        #compute the offset of the swc relative to the image\n",
    "        offset_diff = np.subtract(swc_offset, im_offset)\n",
    "        G = df_to_graph(df)\n",
    "\n",
    "        paths = graph_to_paths(G)\n",
    "\n",
    "        # for every path in that swc\n",
    "        \n",
    "        for path_num, p in enumerate(paths):\n",
    "            #convert from spatial coordinates to voxel coordinates\n",
    "            pvox = (p + offset_diff) / (scale) * 1000\n",
    "            paths_total.append(pvox)\n",
    "            \n",
    "        #napari_viewer(np.swapaxes(im,0,2), shapes=paths_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paths[0][0])\n",
    "print(paths_total[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
