{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from brainlit.utils import upload, session\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading Brain Images from data in the Octree format.\n",
    "This notebook demonstrates uploading the 2 lowest-resolution brain volumes, as well as a `.swc` segment file.\n",
    "The upload destination could easily be set to a url of a cloud data server such as s3.\n",
    "\n",
    "## 1) Define variables.\n",
    " - `source` and `source_segments` are the root directories of the octree-formatted data and swc files.\n",
    " - `p` is the prefix string. `file://` indicates a filepath, while `s3://` or `gc://` indicate URLs.\n",
    " - `dest` and `dest_segments` are the destinations for the uploads (in this case, filepaths).\n",
    " - `num_res` denotes the number of resolutions to upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = (Path().resolve().parents[2] / \"data\" / \"data_octree\").as_posix()\n",
    "dest = (Path().resolve().parents[2] / \"data\" / \"upload\").as_uri()\n",
    "dest_segments = (Path().resolve().parents[2] / \"data\" / \"upload_segments\").as_uri()\n",
    "dest_annotation = (Path().resolve().parents[2] / \"data\" / \"upload_annotation\").as_uri()\n",
    "num_res = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Upload the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Creating precomputed volume: 100%|██████████| 1/1 [00:05<00:00,  5.18s/it]\nCreating precomputed volume:   0%|          | 0/8 [00:00<?, ?it/s]\nFinished mip 0, took 5.183950901031494 seconds\nCreating precomputed volume:  62%|██████▎   | 5/8 [00:12<00:07,  2.38s/it]"
    }
   ],
   "source": [
    "upload.upload_volumes(source, dest, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload.upload_segments(source, dest_segments, num_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, voxel_size, img_size, _ = upload.get_volume_info(source, num_res)\n",
    "upload.create_cloud_volume(dest_annotation, img_size, voxel_size, 1, layer_type=\"annotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.algorithms.generate_fragments.tube_seg import tubes_seg\n",
    "sess = NeuroglancerSession(url = dest, url_segments= dest_segments, url_annotation=dest_annotation, mip=0)\n",
    "img, bounds, vertices = sess.pull_vertex_list(2, range(100, 200), expand=True)  # get image containing some data\n",
    "labels = tubes_seg(img, vertices, radius=.1)  # generate labels via tube segmentation\n",
    "sess.push(labels, bounds)  # push labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize your data with NeuroglancerSession and napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudvolume import Bbox\n",
    "from brainlit.utils.swc import graph_to_paths\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 1/1 [00:00<00:00, 518.46it/s]\n"
    }
   ],
   "source": [
    "G_sub = sess.get_segments(2, bounds)\n",
    "paths = graph_to_paths(G_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer(ndisplay=3)\n",
    "    viewer.add_image(img)\n",
    "    viewer.add_labels(labels)\n",
    "    viewer.add_shapes(data=paths, shape_type='path', edge_width=0.1, edge_color='blue', opacity=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('brainlit3.8': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596934409212"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}