{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from brainlit.utils.ngl_pipeline import NeuroglancerSession\n",
    "from brainlit.utils import upload_to_neuroglancer as upload\n",
    "from brainlit.utils import upload_skeleton\n",
    "import numpy as np\n",
    "import napari\n",
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../tests/data_octree\"\n",
    "dest_dir = \"./test_precomputed\"\n",
    "\n",
    "num_res = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Brain Images in the Octree Format\n",
    "## This is a script for uploading entire brain volumes, or uploading specific resolutions onto AWS or a local directory. \n",
    "## Data must be tif files arranged in folders where the highest level corresponds to a single, low res image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files should be arranged as octree with 1-8 indicating volume octant, Binary paths are used to stitch together images according to resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got files and binary representations of paths.\ngot dimensions of volume\nLow res files: []\n\nHigh res files: [['..', '..', '..', 'tests', 'data_octree', 'default.0.tif']]\n---\nSingle image binary: []\n\nMultiple image binaries: [[]]\n"
    }
   ],
   "source": [
    "files, bin_paths, vox_size, tiff_dims = upload.get_volume_info(data_dir, num_res, channel = 0)\n",
    "print(\"Low res files: \" + str(files[0]))\n",
    "print(\"\\nHigh res files: \" + str(files[1]))\n",
    "print(\"---\")\n",
    "print(\"Single image binary: \" + str(bin_paths[0]))\n",
    "print(\"\\nMultiple image binaries: \" + str(bin_paths[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudvolume image layers are created with the number of resolutions in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of volumes: 2\nmips: 1 and 0\nVolumes info: {'data_type': 'uint16', 'num_channels': 1, 'scales': [{'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '6173_6173_6173', 'resolution': [6173, 6173, 6173], 'size': [1056, 800, 416], 'voxel_offset': [0, 0, 0]}, {'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '12346_12346_12346', 'resolution': [12346, 12346, 12346], 'size': [528, 400, 208], 'voxel_offset': [0, 0, 0]}], 'type': 'image'}\n---\nHigh res volume info: {'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '6173_6173_6173', 'resolution': [6173, 6173, 6173], 'size': [1056, 800, 416], 'voxel_offset': [0, 0, 0]}\n\nLow res volume info: {'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '12346_12346_12346', 'resolution': [12346, 12346, 12346], 'size': [528, 400, 208], 'voxel_offset': [0, 0, 0]}\n"
    }
   ],
   "source": [
    "vols = upload.create_image_layer(\"file://\" + dest_dir,tiff_dims, vox_size, num_res)\n",
    "print(\"Number of volumes: \" + str(len(vols)))\n",
    "print(\"mips: \" + str(vols[0].mip) + ' and ' + str(vols[1].mip))\n",
    "print(\"Volumes info: \" + str(vols[0].info))\n",
    "print(\"---\")\n",
    "print(\"High res volume info: \" + str(vols[0].info['scales'][0]))\n",
    "print(\"\\nLow res volume info: \" + str(vols[1].info['scales'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading can be done with either Joblib parallel or non-parrallel sequential if the cpu power isn't there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "u1=upload.upload_chunks(vols[0], files[0], bin_paths[0], parallel=False) # Low res\n",
    "u2=upload.upload_chunks(vols[1], files[1], bin_paths[1], parallel=False) # High res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize your data with NeuroglancerSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\n"
    }
   ],
   "source": [
    "\n",
    "ngl_sess = NeuroglancerSession(mip = 1, url = \"file://\" + dest_dir)\n",
    "from cloudvolume import Bbox\n",
    "img = ngl_sess.pull_bounds_img(Bbox((0,0,0), (200,200,200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    ngl_sess.napari_viewer(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading Neuron traces in .swc format locally\n",
    "swc_dir = \"../../../tests/2018-08-01_G-002_consensus.swc\"\n",
    "dest_dir_skel = \"./test_precomputed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Uploading: 100%|██████████| 1/1 [00:00<00:00, 122.01it/s]\n"
    }
   ],
   "source": [
    "skel = upload_skeleton.swc2skeleton(swc_dir)\n",
    "vol = upload_skeleton.create_skeleton_layer(\n",
    "    \"file://\"+dest_dir_skel, vox_size, tiff_dims, num_res\n",
    ")\n",
    "vol.skeleton.upload(skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngl_sess = NeuroglancerSession(mip = 0, url = \"file://\" + dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ngl_sess.pull_voxel(2, 6, nx=10, ny=10, nz=10) # currently mip mismatch and scale mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cloudvolume import Bbox\n",
    "def get_local_volume_around_vertex(ngl_sess, SEGID=2, VID=6, radius=10):\n",
    "    skel = ngl_sess.cv.skeleton.get(SEGID)\n",
    "    vertex = skel.vertices[VID]\n",
    "    scales = np.multiply(ngl_sess.cv.scales[1][\"resolution\"],2**4) # incomplete data example\n",
    "    voxel = np.round(np.divide(vertex, scales)).astype(int)\n",
    "    bounds = Bbox(voxel, voxel)\n",
    "    seed = bounds.to_list()\n",
    "    shape = [radius, radius, radius]\n",
    "    bounds = Bbox(np.subtract(seed[:3], shape), np.add(np.add(seed[3:], shape), 1))\n",
    "    img = ngl_sess.cv.download(bounds)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading: 100%|██████████| 1/1 [00:00<00:00, 425.17it/s]\nDownloading:   0%|          | 0/1 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/1 [00:00<?, ?it/s]\n"
    }
   ],
   "source": [
    "img = get_local_volume_around_vertex(ngl_sess, VID=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    ngl_sess.napari_viewer(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}