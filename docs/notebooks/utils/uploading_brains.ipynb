{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from brainlit.utils.ngl_pipeline import NeuroglancerSession\n",
    "from brainlit.utils import upload_to_neuroglancer as upload\n",
    "import numpy as np\n",
    "import napari\n",
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../tests/data_octree/\"\n",
    "dest_dir = \"./test_precomputed/\"\n",
    "\n",
    "num_res = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Brain Images in the Octree Format\n",
    "## This is a script for uploading entire brain volumes, or uploading specific resolutions onto AWS or a local directory. \n",
    "## Data must be tif files arranged in folders where the highest level corresponds to a single, low res image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files should be arranged as octree with 1-8 indicating volume octant, Binary paths are used to stitch together images according to resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got files and binary representations of paths.\ngot dimensions of volume\nLow res files: [['..', '..', '..', 'tests', 'data_octree', 'default.0.tif']]\n\nHigh res files: [['..', '..', '..', 'tests', 'data_octree', '7', 'default.0.tif'], ['..', '..', '..', 'tests', 'data_octree', '6', 'default.0.tif'], ['..', '..', '..', 'tests', 'data_octree', '1', 'default.0.tif'], ['..', '..', '..', 'tests', 'data_octree', '8', 'default.0.tif'], ['..', '..', '..', 'tests', 'data_octree', '4', 'default.0.tif'], ['..', '..', '..', 'tests', 'data_octree', '3', 'default.0.tif'], ['..', '..', '..', 'tests', 'data_octree', '2', 'default.0.tif'], ['..', '..', '..', 'tests', 'data_octree', '5', 'default.0.tif']]\n---\nSingle image binary: [[]]\n\nMultiple image binaries: [['110'], ['101'], ['000'], ['111'], ['011'], ['010'], ['001'], ['100']]\n"
    }
   ],
   "source": [
    "files, bin_paths, vox_size, tiff_dims = upload.get_volume_info(data_dir, num_res, channel = 0)\n",
    "print(\"Low res files: \" + str(files[0]))\n",
    "print(\"\\nHigh res files: \" + str(files[1]))\n",
    "print(\"---\")\n",
    "print(\"Single image binary: \" + str(bin_paths[0]))\n",
    "print(\"\\nMultiple image binaries: \" + str(bin_paths[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloudvolume image layers are created with the number of resolutions in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of volumes: 2\nmips: 1 and 0\nVolumes info: {'data_type': 'uint16', 'num_channels': 1, 'scales': [{'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '6173_6173_6173', 'resolution': [6173, 6173, 6173], 'size': [1056, 800, 416], 'voxel_offset': [0, 0, 0]}, {'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '12346_12346_12346', 'resolution': [12346, 12346, 12346], 'size': [528, 400, 208], 'voxel_offset': [0, 0, 0]}], 'type': 'image'}\n---\nHigh res volume info: {'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '6173_6173_6173', 'resolution': [6173, 6173, 6173], 'size': [1056, 800, 416], 'voxel_offset': [0, 0, 0]}\n\nLow res volume info: {'chunk_sizes': [[66, 50, 52]], 'encoding': 'raw', 'key': '12346_12346_12346', 'resolution': [12346, 12346, 12346], 'size': [528, 400, 208], 'voxel_offset': [0, 0, 0]}\n"
    }
   ],
   "source": [
    "vols = upload.create_image_layer(\"file://\" + dest_dir,tiff_dims, vox_size, num_res)\n",
    "print(\"Number of volumes: \" + str(len(vols)))\n",
    "print(\"mips: \" + str(vols[0].mip) + ' and ' + str(vols[1].mip))\n",
    "print(\"Volumes info: \" + str(vols[0].info))\n",
    "print(\"---\")\n",
    "print(\"High res volume info: \" + str(vols[0].info['scales'][0]))\n",
    "print(\"\\nLow res volume info: \" + str(vols[1].info['scales'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading can be done with either Joblib parallel or non-parrallel sequential if the cpu power isn't there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "u1=upload.upload_chunks(vols[0], files[0], bin_paths[0], parallel=False) # Low res\n",
    "u2=upload.upload_chunks(vols[1], files[1], bin_paths[1], parallel=False) # High res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize your data with NeuroglancerSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Downloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\nDownloading:   0%|          | 0/8 [00:00<?, ?it/s]\n"
    }
   ],
   "source": [
    "\n",
    "ngl_sess = NeuroglancerSession(mip = 1, url = \"file://\" + dest_dir)\n",
    "from cloudvolume import Bbox\n",
    "img = ngl_sess.pull_bounds_img(Bbox((0,0,0), (200,200,200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "49459009492"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "np.sum(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with napari.gui_qt():\n",
    "    ngl_sess.napari_viewer(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}