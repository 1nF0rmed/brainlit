{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from brainlit.viz.visualize import napari_viewer\n",
    "\n",
    "from ffn.utils import bounding_box_pb2\n",
    "from ffn.inference import storage\n",
    "from ffn.inference import inference\n",
    "from ffn.inference import inference_pb2\n",
    "from ffn.inference import inference_flags\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_1\n",
      "it's test img\n",
      "test_10\n",
      "it's test img\n",
      "test_11\n",
      "it's test img\n",
      "test_12\n",
      "it's test img\n",
      "test_13\n",
      "it's test img\n",
      "test_14\n",
      "it's test img\n",
      "test_15\n",
      "it's test img\n",
      "test_16\n",
      "it's test img\n",
      "test_17\n",
      "it's test img\n",
      "test_18\n",
      "it's test img\n",
      "test_19\n",
      "it's test img\n",
      "test_2\n",
      "it's test img\n",
      "test_20\n",
      "it's test img\n",
      "test_21\n",
      "it's test img\n",
      "test_22\n",
      "it's test img\n",
      "test_23\n",
      "it's test img\n",
      "test_24\n",
      "it's test img\n",
      "test_25\n",
      "it's test img\n",
      "test_3\n",
      "it's test img\n",
      "test_4\n",
      "it's test img\n",
      "test_5\n",
      "it's test img\n",
      "test_6\n",
      "it's test img\n",
      "test_7\n",
      "it's test img\n",
      "test_8\n",
      "it's test img\n",
      "test_9\n",
      "it's test img\n",
      "validation_1\n",
      "it's validation img\n",
      "validation_10\n",
      "it's validation img\n",
      "validation_11\n",
      "it's validation img\n",
      "validation_12\n",
      "it's validation img\n",
      "validation_13\n",
      "it's validation img\n",
      "validation_14\n",
      "it's validation img\n",
      "validation_15\n",
      "it's validation img\n",
      "validation_16\n",
      "it's validation img\n",
      "validation_17\n",
      "it's validation img\n",
      "validation_18\n",
      "it's validation img\n",
      "validation_19\n",
      "it's validation img\n",
      "validation_2\n",
      "it's validation img\n",
      "validation_20\n",
      "it's validation img\n",
      "validation_21\n",
      "it's validation img\n",
      "validation_22\n",
      "it's validation img\n",
      "validation_23\n",
      "it's validation img\n",
      "validation_24\n",
      "it's validation img\n",
      "validation_25\n",
      "it's validation img\n",
      "validation_3\n",
      "it's validation img\n",
      "validation_4\n",
      "it's validation img\n",
      "validation_5\n",
      "it's validation img\n",
      "validation_6\n",
      "it's validation img\n",
      "validation_7\n",
      "it's validation img\n",
      "validation_8\n",
      "it's validation img\n",
      "validation_9\n",
      "it's validation img\n"
     ]
    }
   ],
   "source": [
    "base_dir = Path(\"D:/Study/Nuero Data Design/brainlit\")\n",
    "data_dir = base_dir / \"benchmarking_datasets\"\n",
    "im_dir = data_dir / \"Images\"\n",
    "mask_dir = base_dir / \"benchmarking_masks\"\n",
    "gfp_files = list(im_dir.glob(\"**/*.tif\"))\n",
    "save_path = \"C:/Users/Tanch/ffn/brainlit/images\"\n",
    "test_path = save_path + \"/test\"\n",
    "validation_path = save_path + \"/validation\"\n",
    "if not os.path.exists(test_path):\n",
    "    os.makedirs(test_path)\n",
    "if not os.path.exists(validation_path):\n",
    "    os.makedirs(validation_path)\n",
    "\n",
    "for im_num, im_path in enumerate(gfp_files):\n",
    "    file_name = im_path.parts[-1][:-8]\n",
    "    print(file_name)\n",
    "    if file_name[:10] != \"validation\":\n",
    "        print(\"it's test img\")\n",
    "        im = io.imread(im_path, plugin=\"tifffile\")\n",
    "        im = np.swapaxes(im, 0, 2)\n",
    "        mask_file = file_name + \"_mask.tif\"\n",
    "        mask_path = mask_dir / mask_file\n",
    "        mask = io.imread(mask_path, plugin=\"tifffile\")\n",
    "        test_file = test_path + \"/\" + file_name + \".h5\"\n",
    "        with h5py.File(test_file, 'w') as f:\n",
    "            f.create_dataset('raw', data = im, compression = 'gzip') \n",
    "            f.create_dataset('mask', data = mask, compression = 'gzip')\n",
    "    else:\n",
    "        print(\"it's validation img\")\n",
    "        im = io.imread(im_path, plugin=\"tifffile\")\n",
    "        im = np.swapaxes(im, 0, 2)\n",
    "        mask_file = file_name + \"_mask.tif\"\n",
    "        mask_path = mask_dir / mask_file\n",
    "        mask = io.imread(mask_path, plugin=\"tifffile\")\n",
    "        val_file = validation_path + \"/\" + file_name + \".h5\"\n",
    "        with h5py.File(val_file, 'w') as f:\n",
    "            f.create_dataset('raw', data = im, compression = 'gzip') \n",
    "            f.create_dataset('mask', data = mask, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"C:/Users/Tanch/ffn/brainlit/results\"\n",
    "for i in range(25):\n",
    "    i += 1\n",
    "    test_path = result_path + \"/test_\" + str(i)\n",
    "    if not os.path.exists(test_path):\n",
    "        os.makedirs(test_path)\n",
    "    for j in range(25):\n",
    "        j += 1\n",
    "        val_path = test_path + \"/validation_\" + str(j)\n",
    "        if not os.path.exists(val_path):\n",
    "            os.makedirs(val_path)\n",
    "        val_path += \"/0\"\n",
    "        if not os.path.exists(val_path):\n",
    "            os.makedirs(val_path)\n",
    "test_path = result_path + \"/10_images\"\n",
    "for j in range(25):\n",
    "    j += 1\n",
    "    val_path = test_path + \"/validation_\" + str(j)\n",
    "    if not os.path.exists(val_path):\n",
    "        os.makedirs(val_path)\n",
    "    val_path += \"/0\"\n",
    "    if not os.path.exists(val_path):\n",
    "        os.makedirs(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x220421737c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "napari_viewer(im, labels = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:833: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:833: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:887: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n",
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:887: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:888: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:888: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:889: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:889: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\training\\model.py:78: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\training\\model.py:78: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\training\\models\\convstack_3d.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\training\\models\\convstack_3d.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\brainlit\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\brainlit\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\training\\models\\convstack_3d.py:85: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\training\\models\\convstack_3d.py:85: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:414: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:414: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['mask', 'raw']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:589: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.any(self.segmentation[sel] > 0):\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:421: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[[slice(s, e) for s, e in zip(start, end)]])\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:382: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  img = self.image[[slice(s, e) for s, e in zip(start, end)]]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:454: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  old_seed = self.seed[sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:472: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[sel] = logits\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\movement.py:80: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  face_prob = prob_map[face_sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:627: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask = self.seed[sel] >= self.options.segment_threshold\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:631: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  overlapped_ids, counts = np.unique(self.segmentation[sel][mask],\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:637: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask &= self.segmentation[sel] <= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['mask', 'raw']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:589: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.any(self.segmentation[sel] > 0):\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:421: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[[slice(s, e) for s, e in zip(start, end)]])\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:382: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  img = self.image[[slice(s, e) for s, e in zip(start, end)]]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:454: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  old_seed = self.seed[sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:472: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[sel] = logits\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\movement.py:80: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  face_prob = prob_map[face_sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:627: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask = self.seed[sel] >= self.options.segment_threshold\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:631: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  overlapped_ids, counts = np.unique(self.segmentation[sel][mask],\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:637: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask &= self.segmentation[sel] <= 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-84e73aeac773>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mtext_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbounding_box\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mseg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_segmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'brainlit/results/test_1/validation_%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mim_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ffn\\ffn\\inference\\inference.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, corner, subvol_size, reset_counters)\u001b[0m\n\u001b[0;32m   1208\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1210\u001b[1;33m     \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_seed_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubvol_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1211\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_segmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malignment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ffn\\ffn\\inference\\inference.py\u001b[0m in \u001b[0;36msegment_all\u001b[1;34m(self, seed_policy)\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;31m# Try segmentation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[0mseg_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m         \u001b[0mnum_iters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[0mt_seg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mseg_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ffn\\ffn\\inference\\inference.py\u001b[0m in \u001b[0;36msegment_at\u001b[1;34m(self, start_pos, dynamic_image, vis_update_every, vis_fixed_z)\u001b[0m\n\u001b[0;32m    526\u001b[0m           \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_min_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_min_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ffn\\ffn\\inference\\inference.py\u001b[0m in \u001b[0;36mupdate_at\u001b[1;34m(self, pos, start_pos)\u001b[0m\n\u001b[0;32m    429\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_SELF_CONSISTENT_ITERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         (prob, logits), fetches = self.predict(pos, logit_seed,\n\u001b[1;32m--> 431\u001b[1;33m                                                extra_fetches=extra_fetches)\n\u001b[0m\u001b[0;32m    432\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsistency_threshold\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m           \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ffn\\ffn\\inference\\inference.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, pos, logit_seed, extra_fetches)\u001b[0m\n\u001b[0;32m    391\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtimer_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inference'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         fetches = self.executor.predict(self._exec_client_id,\n\u001b[1;32m--> 393\u001b[1;33m                                         logit_seed, img, extra_fetches)\n\u001b[0m\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_last_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ffn\\ffn\\inference\\executor.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, client_id, seed, image, fetches)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtimer_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'client-wait'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\brainlit\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\brainlit\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "napari_view = True\n",
    "for im_num in range(25):\n",
    "    im_num += 1\n",
    "    config = '''image {\n",
    "      hdf5: \"brainlit/images/validation/validation_%d.h5:raw\"\n",
    "    }\n",
    "    image_mean: 64\n",
    "    image_stddev: 33\n",
    "    checkpoint_interval: 1800\n",
    "    seed_policy: \"PolicyPeaks\"\n",
    "    model_checkpoint_path: \"brainlit/models/test_1/model.ckpt-10000\"\n",
    "    model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "    model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "    segmentation_output_dir: \"brainlit/results/test_1/validation_%d\"\n",
    "    inference_options {\n",
    "      init_activation: 0.95\n",
    "      pad_value: 0.05\n",
    "      move_threshold: 0.9\n",
    "      min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "      segment_threshold: 0.6\n",
    "      min_segment_size: 1000\n",
    "    }''' % (im_num, im_num)\n",
    "    req = inference_pb2.InferenceRequest()\n",
    "    _ = text_format.Parse(config, req)\n",
    "    \n",
    "    runner = inference.Runner()\n",
    "    runner.start(req)\n",
    "    canvas, alignment = runner.make_canvas((0, 0, 0), (330, 330, 100))\n",
    "    \n",
    "    bbox = bounding_box_pb2.BoundingBox()\n",
    "    bounding_box = 'start { x:0 y:0 z:0 } size { x:330 y:330 z:100 }'\n",
    "    text_format.Parse(bounding_box, bbox)\n",
    "    \n",
    "    runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))\n",
    "    \n",
    "    seg, _ = storage.load_segmentation('brainlit/results/test_1/validation_%d' % im_num, (0, 0, 0))\n",
    "    seg2 = seg\n",
    "    seg2 = np.int64(seg2 > 0)\n",
    "    \n",
    "    filename = \"brainlit/images/validation/validation_%d.h5\" % im_num\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        # List all groups\n",
    "        print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "        # Get the data\n",
    "        data = list(f[\"raw\"])\n",
    "        img = np.array(data)\n",
    "        data = list(f[\"mask\"])\n",
    "        mask = np.array(data)\n",
    "\n",
    "    if napari_view:\n",
    "        napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
