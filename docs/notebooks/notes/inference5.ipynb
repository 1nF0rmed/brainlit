{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from ffn.inference import inference\n",
    "from ffn.inference import inference_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\brainlit\\lib\\site-packages\\napari\\__init__.py:44: UserWarning: \n",
      "    napari was tested with QT library `>=5.12.3`.\n",
      "    The version installed is 5.9.6. Please report any issues with this\n",
      "    specific QT version at https://github.com/Napari/napari/issues.\n",
      "    \n",
      "  warn(message=warn_message)\n"
     ]
    }
   ],
   "source": [
    "from brainlit.utils.session import NeuroglancerSession\n",
    "from brainlit.utils.swc import graph_to_paths\n",
    "import napari\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def napari_viewer(img, labels=None, shapes=None, label_name=\"Segmentation\"):\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.view_image(np.squeeze(np.array(img)))\n",
    "        if labels is not None:\n",
    "            if isinstance(labels, list):\n",
    "                for l,label in enumerate(labels):\n",
    "                    name = label_name + \"_\" + str(l) \n",
    "                    viewer.add_labels(label, name=name)\n",
    "            else:\n",
    "                viewer.add_labels(labels, name=label_name)\n",
    "        if shapes is not None:\n",
    "            viewer.add_shapes(\n",
    "                data=shapes, shape_type=\"path\", edge_color=\"blue\", name=\"Skeleton\"\n",
    "            )\n",
    "        return viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"s3://open-neurodata/brainlit/brain1\"\n",
    "dir_segments = \"s3://open-neurodata/brainlit/brain1_segments\"\n",
    "mip = 0\n",
    "v_id = 0\n",
    "radius = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████| 24/24 [00:02<00:00,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Downloaded volume is of shape (151, 151, 151), with total intensity 4946609.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get image and center point\n",
    "ngl_sess = NeuroglancerSession(mip = mip, url = dir, url_segments=dir_segments)\n",
    "img, bbox, vox = ngl_sess.pull_voxel(2, v_id, radius)\n",
    "print(f\"\\n\\nDownloaded volume is of shape {img.shape}, with total intensity {sum(sum(sum(img)))}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "filename = \"brainlit/images/image1.h5\"\n",
    "with h5py.File(filename, 'w') as f:\n",
    "  f.create_dataset('raw', data=img, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = '''image {\n",
    "  hdf5: \"brainlit/images/image1.h5:raw\"\n",
    "}\n",
    "image_mean: 128\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"models/fib25/model.ckpt-27465036\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 12, \\\\\"fov_size\\\\\": [33, 33, 33], \\\\\"deltas\\\\\": [8, 8, 8]}\"\n",
    "segmentation_output_dir: \"brainlit/results/model_0\"\n",
    "inference_options {\n",
    "  init_activation: 0.95\n",
    "  pad_value: 0.05\n",
    "  move_threshold: 0.9\n",
    "  min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "  segment_threshold: 0.6\n",
    "  min_segment_size: 1000\n",
    "}'''\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/fib25/model.ckpt-27465036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/fib25/model.ckpt-27465036\n"
     ]
    }
   ],
   "source": [
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (151, 151, 151))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAAEvCAIAAACbvNCPAAAJVUlEQVR4nO3dQWhkdx3A8d/LZGeSbNOutimlrW5FcaldSlG0ClqtIh5UWkHtQY8epOKtSD2pR0EFe/IgQkEselqKVKUHpYjQSsEtWDx0YUv10Nq13e1mkzdNdjxkm02260xmnMn7/V8+H4YyTaaPX3jznTfz5r3XCMp34mi/6RGYgrmmBwAuUSNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZDHf9AAz0e/v+tdut6E5+N+uWEezUNx6b+e2sduNweDyfRK6s3vD+t/v/HD3lq2Vdf7Pn4mIwSAGgxhsdH5/rF7oRnec21L5K7pqeoBJHIp4c+gDdr7uDjY6vaXNhYj1GU/VoBNH+/e/WN6Tcfjmcfv19JLNTnQ2q3GesMW9EBe5bRyeYuxekUeWLkarUyxUFXFv946r/mowiI3/vPPm3nyvF9u3I0sXe73odqPXjWu6sdKd+0b3W6cf+s3p7zy2z5Ozy8jXx37/8q2dn4x3O3F09h/Cpu1PH3qtrnetqa1bXV+6nXvu+Eoc2n7829fjzbHwyxvOX3UhWzf2w1g1HgQl1hgRq6feXdcREVv//P78Hz4Wt0+2qMWo1JjRrbG084X2ICi0xm9XP9paQVtbwEOT7sY4FPHjhefUmNGX44GDtj4KrXG6qrj0+lvu2i9yL85wj/zslqZHoAGDiMEger2m52CntVevLffVcTK2jVcodO23cNs4t3yu6RHYq3r1IOzz3qsW1kgp7o/7nv/6X5ueglkq+nP8ZAp9p7oS3Rnt9N56DhTHtpHG3Bo3XTObnS6DfmkHxUWEGmnQz7/4xMZslvzR5Ztms2DGtPOd6iAu3dqt0Heqx+L62S3cO9V9shjDDuXvnzq2f6MwqcWoOtG5LjqzWPhMFjp7Rda49razbXaav/6V/RuFSa3H4PNzPzwXm7NY+EwWOntF1jjc6jOf3L5fvXUjm0HEqYu//WC8p+lBEmlhjad++pOmR2C0KqIby0+9eDCO6z+wHrvxgu8b87stlusLndmdZFPi2m/htvHRV77Q9AiM9nKcr+bHu7JG67WwxlfjdNMjMNpKHG56hHRaWONrcabpERjtpTjf9AjptLDGV+ONpkdgtO1D145E59ppPw/r1UOjH5RPC89n2dhx7E11AA7EKdT27puX682IaZ8lPD/yuoIZtXDbWO8I8OyzdzU3CMMcfutr4KqKqoonj69Oa4dOvV4VunOohTVe3HG/d8fJsf7b22Pl5Fefnu48XFVn90EZ9zx7eHlaz8aq1PdDRda4MPS3O1fFiw//aqwlr0f97398YIKRGNdKLF/xk96UPjcVumFsrctXcLww3vHDhR4zUOK3/xFXXnDx7NMfue1tiY5l61iCco/9KHLb+N64bo+vor2lzYh47al7ZjoPk3nhwd9t3/9E9/3X3f3M6f9vf7gLxjVj+A7sXdeQX50v8WVyLIVuG3eeiVqvzZ07efyz8fH1cwtbR8xdeVudv8oP66jrWIj4bufX18Zc6ddTLc8tsThygz7x6W2FrsVCa9zSmfbpiN2Iv33lmRLXI21QdI1sK/JzI7SSGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohi+rE0X7TMwAREVXTAzAFXlLbwTtVyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZBFO2usIj4ddz95fDUiFqNqehzYk/mmB5iyKmK9jqqKiKcjDvcj7uquPB+vND0XjNa2bePa60vV7m3hv+JMQ7PAeNpW48KRC91uDAaXf3I2NpsbB8ZQZI2dpgeAWSiyxpEbu8qOGwpUZI1ao5WKrHEw+iFQniJrHO7G6G7fHwiXcrSwxgfnH9++f3fvXQ1OAmNp4UewtTPLneU3tu53u8Mf2xInjvabHoEpaOG2ce6aN5oeASbRwhqhUGqELNQIWagRsiiyxsWhh771Tx3bv1FgeoqscW3ot/qvP/G1/RsFpqfIGof70kOPNj0CTKKFNZ6MU02PAJNoYY1vNj0ATKaFNUKh1AhZtLPG7V2u7fzzaKmWP11/8Y7Xmx4B9qrIGvd+GtjmRReMoxhF1rj3E/ofPnvT3hdbr7btWs+UpcgaR24bH+jdt3Xnn/UY33csHN6YdCKYghae+x8RdX35SNY9nv4/F7FWx2IvBgVeBcu5/+1Q5LZxpF4v3tc9PBiMcSWO9X5ExMUCU6Q1WlhjFVHX8UJ/tar29Od9s/pBvx8RUVXR70ffZoaGlFrjzv0tW3/D9nvuz8W9279a74/+3wQ8Un9vioPBxIqscSUObUT03ipwELEY1V8+9VJdR78fj/f/uPP0x7V+1PUYC3cJVprSzr04B429OO1Q5LYRWkmNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZCFGiELNUIWaoQs1AhZqBGyUCNkoUbIQo2QhRohCzVCFmqELNQIWagRslAjZKFGyEKNkIUaIQs1QhZqhCzUCFmoEbJQI2ShRshCjZDFfwHhGiidCBkFNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a single segment, starting from the specified origin point.\n",
    "canvas.segment_at((75, 75, 75),  # zyx\n",
    "                  dynamic_image=inference.DynamicImage(),\n",
    "                  vis_update_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffn.utils import bounding_box_pb2\n",
    "from ffn.inference import inference\n",
    "from ffn.inference import inference_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start {\n",
       "  x: 0\n",
       "  y: 0\n",
       "  z: 0\n",
       "}\n",
       "size {\n",
       "  x: 151\n",
       "  y: 151\n",
       "  z: 151\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:151 y:151 z:151 }'\n",
    "text_format.Parse(bounding_box, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:589: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.any(self.segmentation[sel] > 0):\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:421: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[[slice(s, e) for s, e in zip(start, end)]])\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:382: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  img = self.image[[slice(s, e) for s, e in zip(start, end)]]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:454: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  old_seed = self.seed[sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:472: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[sel] = logits\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\movement.py:80: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  face_prob = prob_map[face_sel]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ffn.inference.inference.Canvas at 0x1acd21a5ec8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x),\n",
    "             (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:414: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:414: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ffn.inference import storage\n",
    "\n",
    "seg, _ = storage.load_segmentation('brainlit/results/model_0', (0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x1acd215a508>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "napari_viewer(img, labels=seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
