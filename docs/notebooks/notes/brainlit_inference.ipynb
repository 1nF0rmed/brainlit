{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from brainlit.viz.visualize import napari_viewer\n",
    "\n",
    "from ffn.utils import bounding_box_pb2\n",
    "from ffn.inference import storage\n",
    "from ffn.inference import inference\n",
    "from ffn.inference import inference_pb2\n",
    "from ffn.inference import inference_flags\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "from skimage import io\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "config = '''image {\n",
    "  hdf5: \"brainlit/images/image1.h5:raw\"\n",
    "}\n",
    "image_mean: 64\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"brainlit/models/test_1/model.ckpt-10000\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "segmentation_output_dir: \"brainlit/results/test_1/tutorial\"\n",
    "inference_options {\n",
    "  init_activation: 0.95\n",
    "  pad_value: 0.05\n",
    "  move_threshold: 0.9\n",
    "  min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "  segment_threshold: 0.6\n",
    "  min_segment_size: 1000\n",
    "}'''\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)\n",
    "\n",
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (150, 150, 150))\n",
    "\n",
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:150 y:150 z:150 }'\n",
    "text_format.Parse(bounding_box, bbox)\n",
    "\n",
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['raw']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x24d84114588>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "filename = \"brainlit/images/image1.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[\"raw\"])\n",
    "    img = np.array(data)\n",
    "    # data = list(f[\"mask\"])\n",
    "    # mask = np.array(data)\n",
    "    \n",
    "seg, _ = storage.load_segmentation('brainlit/results/test_1/tutorial', (0, 0, 0))\n",
    "seg2 = seg\n",
    "seg2 = np.int64(seg2>0)\n",
    "sum(sum(sum(seg2)))\n",
    "napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "im_num = 1\n",
    "config = '''image {\n",
    "    hdf5: \"brainlit/images/validation/validation_%d.h5:raw\"\n",
    "}\n",
    "image_mean: 64\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"brainlit/models/test_1/model.ckpt-10000\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "segmentation_output_dir: \"brainlit/results/test_1/validation_%d\"\n",
    "inference_options {\n",
    "    init_activation: 0.95\n",
    "    pad_value: 0.05\n",
    "    move_threshold: 0.9\n",
    "    min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "    segment_threshold: 0.6\n",
    "    min_segment_size: 1000\n",
    "}''' % (im_num, im_num)\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)\n",
    "\n",
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (330, 330, 100))\n",
    "\n",
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:330 y:330 z:100 }'\n",
    "text_format.Parse(bounding_box, bbox)\n",
    "    \n",
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['mask', 'raw']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x24d8d29c5c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "filename = \"brainlit/images/validation/validation_%d.h5\" % im_num\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[\"raw\"])\n",
    "    img = np.array(data)\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    data = list(f[\"mask\"])\n",
    "    mask = np.array(data)\n",
    "\n",
    "seg, _ = storage.load_segmentation('brainlit/results/test_1/validation_%d' % im_num, (0, 0, 0))\n",
    "seg2 = seg\n",
    "seg2 = np.int64(seg2 > 0)\n",
    "sum(sum(sum(seg2)))\n",
    "napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/test_1/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ffn.inference.inference.Canvas at 0x24d84114c88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "im_num = 1\n",
    "config = '''image {\n",
    "    hdf5: \"brainlit/images/test/test_1.h5:raw\"\n",
    "}\n",
    "image_mean: 64\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"brainlit/models/test_1/model.ckpt-10000\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "segmentation_output_dir: \"brainlit/results/test_1\"\n",
    "inference_options {\n",
    "    init_activation: 0.95\n",
    "    pad_value: 0.05\n",
    "    move_threshold: 0.9\n",
    "    min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "    segment_threshold: 0.6\n",
    "    min_segment_size: 1000\n",
    "}'''\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)\n",
    "\n",
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (330, 330, 100))\n",
    "\n",
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:330 y:330 z:100 }'\n",
    "text_format.Parse(bounding_box, bbox)\n",
    "    \n",
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['mask', 'raw']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x24d8c835e88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "filename = \"brainlit/images/test/test_1.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[\"raw\"])\n",
    "    img = np.array(data)\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    data = list(f[\"mask\"])\n",
    "    mask = np.array(data)\n",
    "\n",
    "seg, _ = storage.load_segmentation('brainlit/results/test_1', (0, 0, 0))\n",
    "seg2 = seg\n",
    "seg2 = np.int64(seg2 > 0)\n",
    "sum(sum(sum(seg2)))\n",
    "napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/10_images/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/10_images/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "config = '''image {\n",
    "    hdf5: \"brainlit/images/image1.h5:raw\"\n",
    "}\n",
    "image_mean: 64\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"brainlit/models/10_images/model.ckpt-10000\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "segmentation_output_dir: \"brainlit/results/10_images\"\n",
    "inference_options {\n",
    "    init_activation: 0.95\n",
    "    pad_value: 0.05\n",
    "    move_threshold: 0.9\n",
    "    min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "    segment_threshold: 0.6\n",
    "    min_segment_size: 1000\n",
    "}'''\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)\n",
    "\n",
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (150, 150, 150))\n",
    "\n",
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:150 y:150 z:150 }'\n",
    "text_format.Parse(bounding_box, bbox)\n",
    "    \n",
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['raw']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x1be2ba3acc8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"brainlit/images/image1.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[\"raw\"])\n",
    "    img = np.array(data)\n",
    "    # data = list(f[\"mask\"])\n",
    "    # mask = np.array(data)\n",
    "    \n",
    "seg, _ = storage.load_segmentation('brainlit/results/10_images', (0, 0, 0))\n",
    "seg2 = seg\n",
    "seg2 = np.int64(seg2 > 0)\n",
    "napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/10_images/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/10_images/model.ckpt-10000\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:589: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.any(self.segmentation[sel] > 0):\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:421: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[[slice(s, e) for s, e in zip(start, end)]])\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:382: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  img = self.image[[slice(s, e) for s, e in zip(start, end)]]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:454: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  old_seed = self.seed[sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:472: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[sel] = logits\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\movement.py:80: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  face_prob = prob_map[face_sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:627: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask = self.seed[sel] >= self.options.segment_threshold\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:631: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  overlapped_ids, counts = np.unique(self.segmentation[sel][mask],\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:637: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask &= self.segmentation[sel] <= 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ffn.inference.inference.Canvas at 0x1be31f78608>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_num = 2\n",
    "config = '''image {\n",
    "    hdf5: \"brainlit/images/validation/validation_%d.h5:raw\"\n",
    "}\n",
    "image_mean: 64\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"brainlit/models/10_images/model.ckpt-10000\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "segmentation_output_dir: \"brainlit/results/10_images/validation_%d\"\n",
    "inference_options {\n",
    "    init_activation: 0.95\n",
    "    pad_value: 0.05\n",
    "    move_threshold: 0.9\n",
    "    min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "    segment_threshold: 0.6\n",
    "    min_segment_size: 1000\n",
    "}''' % (im_num, im_num)\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)\n",
    "\n",
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (330, 330, 100))\n",
    "\n",
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:330 y:330 z:100 }'\n",
    "text_format.Parse(bounding_box, bbox)\n",
    "    \n",
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['mask', 'raw']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x1be2ee53048>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"brainlit/images/validation/validation_%d.h5\" % im_num\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[\"raw\"])\n",
    "    img = np.array(data)\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    data = list(f[\"mask\"])\n",
    "    mask = np.array(data)\n",
    "    \n",
    "seg, _ = storage.load_segmentation('brainlit/results/10_images/validation_%d' % im_num, (0, 0, 0))\n",
    "seg2 = seg\n",
    "seg2 = np.int64(seg2 > 0)\n",
    "napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(seg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/5_images/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/5_images/model.ckpt-10000\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:589: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.any(self.segmentation[sel] > 0):\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:421: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[[slice(s, e) for s, e in zip(start, end)]])\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:382: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  img = self.image[[slice(s, e) for s, e in zip(start, end)]]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:454: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  old_seed = self.seed[sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:472: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[sel] = logits\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\movement.py:80: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  face_prob = prob_map[face_sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:627: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask = self.seed[sel] >= self.options.segment_threshold\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:631: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  overlapped_ids, counts = np.unique(self.segmentation[sel][mask],\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:637: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask &= self.segmentation[sel] <= 0\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:658: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.segmentation[sel][mask] = self._max_id\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:660: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  expit(self.seed[sel][mask]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:128: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:95: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:96: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:1215: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ffn.inference.inference.Canvas at 0x1be2f127208>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = '''image {\n",
    "  hdf5: \"brainlit/images/image1.h5:raw\"\n",
    "}\n",
    "image_mean: 64\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"brainlit/models/5_images/model.ckpt-10000\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "segmentation_output_dir: \"brainlit/results/5_images/\"\n",
    "inference_options {\n",
    "  init_activation: 0.95\n",
    "  pad_value: 0.05\n",
    "  move_threshold: 0.9\n",
    "  min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "  segment_threshold: 0.6\n",
    "  min_segment_size: 1000\n",
    "}'''\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)\n",
    "\n",
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (150, 150, 150))\n",
    "\n",
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:150 y:150 z:150 }'\n",
    "text_format.Parse(bounding_box, bbox)\n",
    "\n",
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['raw']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x1be3d486588>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"brainlit/images/image1.h5\"\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[\"raw\"])\n",
    "    img = np.array(data)\n",
    "    # data = list(f[\"mask\"])\n",
    "    # mask = np.array(data)\n",
    "    \n",
    "seg, _ = storage.load_segmentation('brainlit/results/5_images', (0, 0, 0))\n",
    "seg2 = seg\n",
    "seg2 = np.int64(seg2 > 0)\n",
    "napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2417779.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(seg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\storage.py:62: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  volume = h5py.File(path[0])[path[1]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/5_images/model.ckpt-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from brainlit/models/5_images/model.ckpt-10000\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:589: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  if np.any(self.segmentation[sel] > 0):\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:421: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[[slice(s, e) for s, e in zip(start, end)]])\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:382: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  img = self.image[[slice(s, e) for s, e in zip(start, end)]]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:454: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  old_seed = self.seed[sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:472: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  self.seed[sel] = logits\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\movement.py:80: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  face_prob = prob_map[face_sel]\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:627: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask = self.seed[sel] >= self.options.segment_threshold\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:631: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  overlapped_ids, counts = np.unique(self.segmentation[sel][mask],\n",
      "C:\\Users\\Tanch\\ffn\\ffn\\inference\\inference.py:637: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  mask &= self.segmentation[sel] <= 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ffn.inference.inference.Canvas at 0x1be2f58ca08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_num = 1\n",
    "config = '''image {\n",
    "    hdf5: \"brainlit/images/validation/validation_%d.h5:raw\"\n",
    "}\n",
    "image_mean: 64\n",
    "image_stddev: 33\n",
    "checkpoint_interval: 1800\n",
    "seed_policy: \"PolicyPeaks\"\n",
    "model_checkpoint_path: \"brainlit/models/5_images/model.ckpt-10000\"\n",
    "model_name: \"convstack_3d.ConvStack3DFFNModel\"\n",
    "model_args: \"{\\\\\"depth\\\\\": 6, \\\\\"fov_size\\\\\": [11, 11, 11], \\\\\"deltas\\\\\": [4, 4, 4]}\"\n",
    "segmentation_output_dir: \"brainlit/results/5_images/validation_%d\"\n",
    "inference_options {\n",
    "    init_activation: 0.95\n",
    "    pad_value: 0.05\n",
    "    move_threshold: 0.9\n",
    "    min_boundary_dist { x: 1 y: 1 z: 1}\n",
    "    segment_threshold: 0.6\n",
    "    min_segment_size: 1000\n",
    "}''' % (im_num, im_num)\n",
    "req = inference_pb2.InferenceRequest()\n",
    "_ = text_format.Parse(config, req)\n",
    "\n",
    "runner = inference.Runner()\n",
    "runner.start(req)\n",
    "canvas, alignment = runner.make_canvas((0, 0, 0), (330, 330, 100))\n",
    "\n",
    "bbox = bounding_box_pb2.BoundingBox()\n",
    "bounding_box = 'start { x:0 y:0 z:0 } size { x:330 y:330 z:100 }'\n",
    "text_format.Parse(bounding_box, bbox)\n",
    "    \n",
    "runner.run((bbox.start.z, bbox.start.y, bbox.start.x), (bbox.size.z, bbox.size.y, bbox.size.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['mask', 'raw']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<napari.viewer.Viewer at 0x1be35595188>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"brainlit/images/validation/validation_%d.h5\" % im_num\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "\n",
    "    # Get the data\n",
    "    data = list(f[\"raw\"])\n",
    "    img = np.array(data)\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    data = list(f[\"mask\"])\n",
    "    mask = np.array(data)\n",
    "    \n",
    "seg, _ = storage.load_segmentation('brainlit/results/5_images/validation_%d' % im_num, (0, 0, 0))\n",
    "seg2 = seg\n",
    "seg2 = np.int64(seg2 > 0)\n",
    "napari_viewer(img, labels=seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum(seg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
